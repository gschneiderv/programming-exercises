{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do some basic pre-processing. For example, the passenger names will be tokenized, and ticket names will be splitted in parts.\n",
    "\n",
    "train a Gradient Boosted Trees (GBT) with default parameters\n",
    "\n",
    "train a GBT with improved default parameters\n",
    "\n",
    "tune the parameters of a GBTs\n",
    "\n",
    "train and ensemble many GBTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TF-DF 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "print(f\"Found TF-DF {tfdf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found YDF 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import ydf \n",
    "\n",
    "print(f\"Found YDF {ydf.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trainig set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/Users/gaby/Desktop/Repos/titanic/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/gaby/Desktop/Repos/titanic/test.csv\")\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data_set:\n",
    "\n",
    "We will apply the following transformations on the dataset.\n",
    "\n",
    "Tokenize the names. (For example, \"Braund, Mr. Owen Harris\" will become [\"Braund\", \"Mr.\", \"Owen\", \"Harris\"].)\n",
    "Extract any prefix in the ticket. (For example ticket \"STON/O2. 3101282\" will become \"STON/O2.\" and 3101282.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "#let's do a copy of the original dataset    \n",
    "    df = df.copy()\n",
    "#Now, let's define functions: 1) to normalize the name of the passenger\n",
    "#                             2) to get the ticket's number\n",
    "#                             3) to get the item (if it has a letter o code before the number)\n",
    "    def normalize_name(x):\n",
    "        \"\"\"\n",
    "        Concatenate any number of strings.\n",
    "        The string whose method is called is inserted in between each given string. \n",
    "        The result is returned as a new string.\n",
    "        \"\"\"\n",
    "        return \"\".join([v.strip(\",()[].\\\"'\" )for v in x.split(\" \")])\n",
    "    \n",
    "    def ticket_number(x):\n",
    "        \"\"\"\n",
    "        It recieves an string\n",
    "        returns an string \n",
    "        \"\"\"\n",
    "        return x.split(\" \")[-1]\n",
    "    \n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return 'NONE'\n",
    "        return \"_\".join(items[0:-1])\n",
    "# then, some columns must be added: 1) 'Name'\n",
    "#                                 2) 'Ticket_number' \n",
    "#                                 3) 'Ticket_item'  \n",
    "    df['Name'] = df[\"Name\"].apply(normalize_name)\n",
    "    df['Ticket_number'] = df['Ticket'].apply(ticket_number)\n",
    "    df['Ticket_item'] = df['Ticket'].apply(ticket_item)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_number</th>\n",
       "      <th>Ticket_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>BraundMrOwenHarris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CumingsMrsJohnBradleyFlorenceBriggsThayer</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>HeikkinenMissLaina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>FutrelleMrsJacquesHeathLilyMayPeel</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>113803</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>AllenMrWilliamHenry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>373450</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MoranMrJames</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>330877</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthyMrTimothyJ</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>17463</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PalssonMasterGostaLeonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>349909</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>JohnsonMrsOscarWElisabethVilhelminaBerg</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>347742</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NasserMrsNicholasAdeleAchem</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>237736</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                                       Name  \\\n",
       "0            1         0       3                         BraundMrOwenHarris   \n",
       "1            2         1       1  CumingsMrsJohnBradleyFlorenceBriggsThayer   \n",
       "2            3         1       3                         HeikkinenMissLaina   \n",
       "3            4         1       1         FutrelleMrsJacquesHeathLilyMayPeel   \n",
       "4            5         0       3                        AllenMrWilliamHenry   \n",
       "5            6         0       3                               MoranMrJames   \n",
       "6            7         0       1                         McCarthyMrTimothyJ   \n",
       "7            8         0       3                  PalssonMasterGostaLeonard   \n",
       "8            9         1       3    JohnsonMrsOscarWElisabethVilhelminaBerg   \n",
       "9           10         1       2                NasserMrsNicholasAdeleAchem   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "5    male   NaN      0      0            330877   8.4583   NaN        Q   \n",
       "6    male  54.0      0      0             17463  51.8625   E46        S   \n",
       "7    male   2.0      3      1            349909  21.0750   NaN        S   \n",
       "8  female  27.0      0      2            347742  11.1333   NaN        S   \n",
       "9  female  14.0      1      0            237736  30.0708   NaN        C   \n",
       "\n",
       "  Ticket_number Ticket_item  \n",
       "0         21171         A/5  \n",
       "1         17599          PC  \n",
       "2       3101282    STON/O2.  \n",
       "3        113803        NONE  \n",
       "4        373450        NONE  \n",
       "5        330877        NONE  \n",
       "6         17463        NONE  \n",
       "7        349909        NONE  \n",
       "8        347742        NONE  \n",
       "9        237736        NONE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the names\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    def normalize_name(x):\n",
    "        return \"\".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "    \n",
    "    def ticket_number(x):\n",
    "        return x.split(\" \")[-1]\n",
    "    \n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "        \n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocessed_train_df = preprocess(train_df)\n",
    "preprocessed_serving_df = preprocess(test_df)\n",
    "\n",
    "\n",
    "preprocessed_train_df.head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the list of the input features of the model. Notably, we don't want to train our model on the \"PassengerId\" and \"Ticket\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "inputs_features = list(preprocessed_train_df.columns)\n",
    "\n",
    "inputs_features.remove(\"PassengerId\")\n",
    "inputs_features.remove(\"Ticket\")\n",
    "\n",
    "#Also  we take out the \"y\" value, known as \"Survived\", it's not a feature, it is \"label\"\n",
    "\n",
    "inputs_features.remove(\"Survived\")\n",
    "\n",
    "print(f\"Input Features: {inputs_features}\")\n",
    "print(len(inputs_features))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Pandas dataset to TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_names(features, labels = None):\n",
    "    \"\"\"\n",
    "    Divite the names into tokens. TF-DF can consume text tokens natively.\n",
    "    \"\"\"\n",
    "    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n",
    "    return features, labels\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df, label = \"Survived\").map(tokenize_names)\n",
    "\n",
    "serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with default parameters!!\n",
    "\n",
    "First, we are training a GradientBoostedTreesModel model with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 23-08-16 17:18:31.5313 CEST gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-08-16 17:18:31.5337 CEST gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-08-16 17:18:31.5337 CEST gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "2023-08-16 17:18:31.714093: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "[INFO 23-08-16 17:18:35.0068 CEST kernel.cc:1243] Loading model from path /var/folders/yh/nttnvvwn565_gnd98_z427v80000gp/T/tmpnd_kciyk/model/ with prefix a7b337c148f54a39\n",
      "[INFO 23-08-16 17:18:35.0134 CEST abstract_model.cc:1312] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 23-08-16 17:18:35.0135 CEST kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x164678310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x164678310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Accuracy: 0.8152173757553101 Loss:0.8874466419219971\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    verbose = 0, #very few logs\n",
    "    features = [tfdf.keras.FeatureUsage(name = n) for n in inputs_features], \n",
    "    exclude_non_specified_features = True,   #only use features in \"features\"\n",
    "    random_seed= 1234,  \n",
    ")\n",
    "model.fit(train_ds)\n",
    "\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with improved default parameters\n",
    "\n",
    "-->  use some specific parameters when creating the GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 23-08-16 17:19:24.4793 CEST gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-08-16 17:19:24.4794 CEST gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-08-16 17:19:24.4794 CEST gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 23-08-16 17:19:25.0140 CEST kernel.cc:1243] Loading model from path /var/folders/yh/nttnvvwn565_gnd98_z427v80000gp/T/tmpcbdy6dw7/model/ with prefix 74ab76e7c2db49b0\n",
      "[INFO 23-08-16 17:19:25.0212 CEST decision_forest.cc:660] Model loaded with 47 root(s), 2497 node(s), and 9 input feature(s).\n",
      "[INFO 23-08-16 17:19:25.0213 CEST abstract_model.cc:1312] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 23-08-16 17:19:25.0213 CEST kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77173912525177 Loss: 1.0416638851165771\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    verbose= 0,\n",
    "    features = [tfdf.keras.FeatureUsage(name=n) for n in inputs_features],\n",
    "    exclude_non_specified_features= True,\n",
    "\n",
    "    #num_trees=2000,\n",
    "    \n",
    "    # Only for GBT.\n",
    "    # A bit slower, but great to understand the model.\n",
    "    # compute_permutation_variable_importance=True,\n",
    "    \n",
    "    # Change the default hyper-parameters\n",
    "    # hyperparameter_template=\"benchmark_rank1@v1\",\n",
    "    \n",
    "    #num_trees=1000,\n",
    "    #tuner=tuner\n",
    "    \n",
    "    min_examples = 1,\n",
    "    categorical_algorithm = \"RANDOM\",\n",
    "    #MÁX DEPHT = 4\n",
    "\n",
    "    shrinkage= 0.05,\n",
    "     #num_candidate_attributes_ratio=0.2,\n",
    "\n",
    "    split_axis=\"SPARSE_OBLIQUE\",\n",
    "    sparse_oblique_normalization=\"MIN_MAX\",\n",
    "    sparse_oblique_num_projections_exponent=2.0,\n",
    "    num_trees=2000,\n",
    "    #validation_ratio=0.0,\n",
    "    random_seed=1234,\n",
    "\n",
    ")\n",
    "\n",
    "model.fit(train_ds)\n",
    "\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss: {self_evaluation.loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (11):\n",
      "\tAge\n",
      "\tCabin\n",
      "\tEmbarked\n",
      "\tFare\n",
      "\tName\n",
      "\tParch\n",
      "\tPclass\n",
      "\tSex\n",
      "\tSibSp\n",
      "\tTicket_item\n",
      "\tTicket_number\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.           \"Sex\"  0.949495 ################\n",
      "    2.           \"Age\"  0.382930 ####\n",
      "    3.          \"Fare\"  0.268009 #\n",
      "    4.   \"Ticket_item\"  0.181725 \n",
      "    5. \"Ticket_number\"  0.179416 \n",
      "    6.      \"Embarked\"  0.176179 \n",
      "    7.        \"Pclass\"  0.175175 \n",
      "    8.         \"Parch\"  0.174435 \n",
      "    9.         \"SibSp\"  0.171619 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"Sex\" 46.000000 ################\n",
      "    2. \"Age\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.           \"Age\" 640.000000 ################\n",
      "    2.          \"Fare\" 375.000000 #########\n",
      "    3.   \"Ticket_item\" 67.000000 #\n",
      "    4.           \"Sex\" 50.000000 #\n",
      "    5.         \"Parch\" 27.000000 \n",
      "    6. \"Ticket_number\" 27.000000 \n",
      "    7.      \"Embarked\" 18.000000 \n",
      "    8.        \"Pclass\" 12.000000 \n",
      "    9.         \"SibSp\"  9.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.           \"Sex\" 550.291535 ################\n",
      "    2.           \"Age\" 435.097980 ############\n",
      "    3.          \"Fare\" 325.582416 #########\n",
      "    4.   \"Ticket_item\" 31.974222 \n",
      "    5.        \"Pclass\" 26.654899 \n",
      "    6. \"Ticket_number\" 22.114875 \n",
      "    7.      \"Embarked\" 13.929927 \n",
      "    8.         \"Parch\" 10.901898 \n",
      "    9.         \"SibSp\"  0.976424 \n",
      "\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 1.04166\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 47\n",
      "Total number of nodes: 2497\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 47 Average: 53.1277 StdDev: 5.04287\n",
      "Min: 37 Max: 61 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 37, 38)  1   2.13%   2.13% #\n",
      "[ 38, 39)  0   0.00%   2.13%\n",
      "[ 39, 40)  1   2.13%   4.26% #\n",
      "[ 40, 42)  0   0.00%   4.26%\n",
      "[ 42, 43)  0   0.00%   4.26%\n",
      "[ 43, 44)  2   4.26%   8.51% ##\n",
      "[ 44, 45)  0   0.00%   8.51%\n",
      "[ 45, 47)  0   0.00%   8.51%\n",
      "[ 47, 48)  2   4.26%  12.77% ##\n",
      "[ 48, 49)  0   0.00%  12.77%\n",
      "[ 49, 50)  1   2.13%  14.89% #\n",
      "[ 50, 52)  9  19.15%  34.04% #########\n",
      "[ 52, 53)  0   0.00%  34.04%\n",
      "[ 53, 54)  7  14.89%  48.94% #######\n",
      "[ 54, 55)  0   0.00%  48.94%\n",
      "[ 55, 57) 10  21.28%  70.21% ##########\n",
      "[ 57, 58)  9  19.15%  89.36% #########\n",
      "[ 58, 59)  0   0.00%  89.36%\n",
      "[ 59, 60)  3   6.38%  95.74% ###\n",
      "[ 60, 61]  2   4.26% 100.00% ##\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 1272 Average: 4.85456 StdDev: 0.441636\n",
      "Min: 2 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 2, 3)    2   0.16%   0.16%\n",
      "[ 3, 4)   39   3.07%   3.22%\n",
      "[ 4, 5)  101   7.94%  11.16% #\n",
      "[ 5, 5] 1130  88.84% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 1272 Average: 29.5228 StdDev: 72.4086\n",
      "Min: 1 Max: 482 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   1,  25) 997  78.38%  78.38% ##########\n",
      "[  25,  49) 105   8.25%  86.64% #\n",
      "[  49,  73)  48   3.77%  90.41%\n",
      "[  73,  97)  20   1.57%  91.98%\n",
      "[  97, 121)  10   0.79%  92.77%\n",
      "[ 121, 145)  21   1.65%  94.42%\n",
      "[ 145, 169)  12   0.94%  95.36%\n",
      "[ 169, 193)  12   0.94%  96.31%\n",
      "[ 193, 217)   2   0.16%  96.46%\n",
      "[ 217, 242)   1   0.08%  96.54%\n",
      "[ 242, 266)   4   0.31%  96.86%\n",
      "[ 266, 290)   1   0.08%  96.93%\n",
      "[ 290, 314)   2   0.16%  97.09%\n",
      "[ 314, 338)   4   0.31%  97.41%\n",
      "[ 338, 362)   4   0.31%  97.72%\n",
      "[ 362, 386)  13   1.02%  98.74%\n",
      "[ 386, 410)   8   0.63%  99.37%\n",
      "[ 410, 434)   5   0.39%  99.76%\n",
      "[ 434, 458)   1   0.08%  99.84%\n",
      "[ 458, 482]   2   0.16% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t640 : Age [NUMERICAL]\n",
      "\t375 : Fare [NUMERICAL]\n",
      "\t67 : Ticket_item [CATEGORICAL]\n",
      "\t50 : Sex [CATEGORICAL]\n",
      "\t27 : Ticket_number [CATEGORICAL]\n",
      "\t27 : Parch [NUMERICAL]\n",
      "\t18 : Embarked [CATEGORICAL]\n",
      "\t12 : Pclass [NUMERICAL]\n",
      "\t9 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t46 : Sex [CATEGORICAL]\n",
      "\t1 : Age [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t63 : Age [NUMERICAL]\n",
      "\t47 : Sex [CATEGORICAL]\n",
      "\t26 : Fare [NUMERICAL]\n",
      "\t3 : Pclass [NUMERICAL]\n",
      "\t2 : Ticket_number [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t160 : Age [NUMERICAL]\n",
      "\t87 : Fare [NUMERICAL]\n",
      "\t47 : Sex [CATEGORICAL]\n",
      "\t13 : Ticket_item [CATEGORICAL]\n",
      "\t7 : Ticket_number [CATEGORICAL]\n",
      "\t7 : Embarked [CATEGORICAL]\n",
      "\t3 : Pclass [NUMERICAL]\n",
      "\t3 : Parch [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t330 : Age [NUMERICAL]\n",
      "\t196 : Fare [NUMERICAL]\n",
      "\t47 : Sex [CATEGORICAL]\n",
      "\t30 : Ticket_item [CATEGORICAL]\n",
      "\t23 : Ticket_number [CATEGORICAL]\n",
      "\t12 : Parch [NUMERICAL]\n",
      "\t12 : Embarked [CATEGORICAL]\n",
      "\t8 : Pclass [NUMERICAL]\n",
      "\t2 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t640 : Age [NUMERICAL]\n",
      "\t375 : Fare [NUMERICAL]\n",
      "\t67 : Ticket_item [CATEGORICAL]\n",
      "\t50 : Sex [CATEGORICAL]\n",
      "\t27 : Ticket_number [CATEGORICAL]\n",
      "\t27 : Parch [NUMERICAL]\n",
      "\t18 : Embarked [CATEGORICAL]\n",
      "\t12 : Pclass [NUMERICAL]\n",
      "\t9 : SibSp [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t1063 : ObliqueCondition\n",
      "\t162 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t46 : ContainsBitmapCondition\n",
      "\t1 : ObliqueCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t92 : ObliqueCondition\n",
      "\t49 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t253 : ObliqueCondition\n",
      "\t74 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t548 : ObliqueCondition\n",
      "\t112 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t1063 : ObliqueCondition\n",
      "\t162 : ContainsBitmapCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 47\n",
      "\tIter:1 train-loss:1.267642 valid-loss:1.363407  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:2 train-loss:1.216743 valid-loss:1.328696  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:3 train-loss:1.169566 valid-loss:1.301054  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:4 train-loss:1.126272 valid-loss:1.273848  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:5 train-loss:1.086717 valid-loss:1.247617  train-accuracy:0.795995 valid-accuracy:0.717391\n",
      "\tIter:6 train-loss:1.050167 valid-loss:1.220332  train-accuracy:0.821026 valid-accuracy:0.739130\n",
      "\tIter:16 train-loss:0.795341 valid-loss:1.091500  train-accuracy:0.906133 valid-accuracy:0.750000\n",
      "\tIter:26 train-loss:0.658963 valid-loss:1.053519  train-accuracy:0.917397 valid-accuracy:0.750000\n",
      "\tIter:36 train-loss:0.561657 valid-loss:1.046510  train-accuracy:0.923655 valid-accuracy:0.760870\n",
      "\tIter:46 train-loss:0.504063 valid-loss:1.047233  train-accuracy:0.932416 valid-accuracy:0.760870\n",
      "\tIter:56 train-loss:0.456775 valid-loss:1.066534  train-accuracy:0.936170 valid-accuracy:0.760870\n",
      "\tIter:66 train-loss:0.418636 valid-loss:1.074550  train-accuracy:0.943680 valid-accuracy:0.771739\n",
      "\tIter:76 train-loss:0.392254 valid-loss:1.093215  train-accuracy:0.948686 valid-accuracy:0.771739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE PREDICTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission exported to: /Users/gaby/Desktop/Repos/titanic/gender_submission.csv\n",
      "PassengerId,Survived\n",
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,0\n",
      "899,0\n",
      "900,1\n"
     ]
    }
   ],
   "source": [
    "def prediction_to_kaggle_format(model, threshold = 0.5):\n",
    "    proba_survive = model.predict(serving_ds, verbose=0)[:,0]\n",
    "    return pd.DataFrame({\n",
    "        \"PassengerId\": serving_df[\"PassengerId\"],\n",
    "        \"Survived\": (proba_survive >= threshold).astype(int)\n",
    "    })\n",
    "\n",
    "def make_submission(kaggle_predictions):\n",
    "    path = \"/Users/gaby/Desktop/Repos/titanic/gender_submission.csv\"\n",
    "    kaggle_predictions.to_csv(path, index = False)\n",
    "    print(f\"Submission exported to: {path}\")\n",
    "\n",
    "kaggle_predictions = prediction_to_kaggle_format(model)\n",
    "make_submission(kaggle_predictions)\n",
    "\n",
    "!head /Users/gaby/Desktop/Repos/titanic/gender_submission.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Training a model with hyperparameter tunning\n",
    "\n",
    "Hyper-parameter tuning is enabled by specifying the tuner constructor argument of the model. The tuner object contains all the configuration of the tuner (search space, optimizer, trial and objective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials= 1000)\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [LOCAL])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 7, 8])\n",
    "\n",
    "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge = True)\n",
    "\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
    "\n",
    "#tuner.choice(\"use_hessian_gain\", [True, False])\n",
    "\n",
    "tuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "\n",
    "tuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\n",
    "oblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge = True)\n",
    "oblique_space.choice(\"sparse_oblique_normalization\", \n",
    "                     [\"NONE\", \"STANDARD_DESVIATION\", \"MIN_MAX\"])\n",
    "oblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
